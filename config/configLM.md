# üöÄ LM Studio ‚Äî M·∫´u cURL cho c√°c m√¥ h√¨nh GGUF c·ª•c b·ªô

T√†i li·ªáu n√†y h∆∞·ªõng d·∫´n c√°ch g·ªçi API **LM Studio** (qua `http://localhost:1234/v1/chat/completions`) cho c√°c m√¥ h√¨nh GGUF kh√°c nhau.  
Ch·ªâ c·∫ßn sao ch√©p kh·ªëi l·ªánh t∆∞∆°ng ·ª©ng v√† ch·∫°y trong terminal.
C·∫ßn Load Model tr√™n LM Studio v√†o GPU tr∆∞·ªõc khi s·ª≠ d·ª•ng.

---

## ü¶â Hermes 3 ‚Äî Llama 3.1 8B (Q4_K_M)

**Model file:** `Hermes-3-Llama-3.1-8B.Q4_K_M.gguf`  
**Model ID trong API:** `hermes-3-llama-3.1-8b`

```bash
curl http://localhost:1234/v1/chat/completions   -H "Content-Type: application/json"   -d '{
    "model": "hermes-3-llama-3.1-8b",
    "messages": [
      { "role": "system", "content": "Always answer in rhymes. Today is Thursday" },
      { "role": "user", "content": "What day is it today?" }
    ],
    "temperature": 0.7,
    "max_tokens": -1,
    "stream": false
}'
```

---

## üêâ Qwen 3 ‚Äî 8B (Q6_K)

**Model file:** `Qwen3-8B-Q6_K.gguf`  
**Model ID trong API:** `qwen3-8b`

```bash
curl http://localhost:1234/v1/chat/completions   -H "Content-Type: application/json"   -d '{
    "model": "qwen3-8b",
    "messages": [
      { "role": "system", "content": "Always answer in rhymes. Today is Thursday" },
      { "role": "user", "content": "What day is it today?" }
    ],
    "temperature": 0.7,
    "max_tokens": -1,
    "stream": false
}'
```

---

## üêâ Qwen 3 ‚Äî 14B (Q4_K_M)

**Model file:** `Qwen3-14B-Q4_K_M.gguf`  
**Model ID trong API:** `qwen3-14b`

```bash
curl http://localhost:1234/v1/chat/completions   -H "Content-Type: application/json"   -d '{
    "model": "qwen3-14b",
    "messages": [
      { "role": "system", "content": "Always answer in rhymes. Today is Thursday" },
      { "role": "user", "content": "What day is it today?" }
    ],
    "temperature": 0.7,
    "max_tokens": -1,
    "stream": false
}'
```

---


## ü¶ô Meta Llama 3.1 ‚Äî 8B Instruct (Q5_K_M)

**Model file:** `Meta-Llama-3.1-8B-Instruct-Q5_K_M.gguf`  
**Model ID trong API:** `meta-llama-3.1-8b-instruct@q5_k_m`

```bash
curl http://localhost:1234/v1/chat/completions   -H "Content-Type: application/json"   -d '{
    "model": "meta-llama-3.1-8b-instruct@q5_k_m",
    "messages": [
      { "role": "system", "content": "Always answer in rhymes. Today is Thursday" },
      { "role": "user", "content": "What day is it today?" }
    ],
    "temperature": 0.7,
    "max_tokens": -1,
    "stream": false
}'

```

---

## ü¶ô Meta Llama 3.1 ‚Äî 8B Instruct (Q6_K)

**Model file:** `Meta-Llama-3.1-8B-Instruct-Q6_K.gguf`  
**Model ID trong API:** `meta-llama-3.1-8b-instruct@q6_k`

```bash
curl http://localhost:1234/v1/chat/completions   -H "Content-Type: application/json"   -d '{
    "model": "meta-llama-3.1-8b-instruct@q6_k",
    "messages": [
      { "role": "system", "content": "Always answer in rhymes. Today is Thursday" },
      { "role": "user", "content": "What day is it today?" }
    ],
    "temperature": 0.7,
    "max_tokens": -1,
    "stream": false
}'

```

---

## ü¶ô Meta Llama 3.1 ‚Äî 8B Instruct (Q8_0)

**Model file:** `Meta-Llama-3.1-8B-Instruct-Q8_0.gguf`  
**Model ID trong API:** `meta-llama-3.1-8b-instruct@q8_0`

```bash
curl http://localhost:1234/v1/chat/completions   -H "Content-Type: application/json"   -d '{
    "model": "meta-llama-3.1-8b-instruct@q8_0",
    "messages": [
      { "role": "system", "content": "Always answer in rhymes. Today is Thursday" },
      { "role": "user", "content": "What day is it today?" }
    ],
    "temperature": 0.7,
    "max_tokens": -1,
    "stream": false
}'

```

---

curl http://localhost:1234/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "qwen3-8b",
    "messages": [
      { "role": "system", "content": "Always answer in rhymes. Today is Thursday" },
      { "role": "user", "content": "What day is it today?" }
    ],
    "temperature": 0.7,
    "max_tokens": -1,
    "stream": false
}'
