
# ğŸš€ LM Studio â€” GGUF æœ¬åœ°æ¨¡å‹ curl ç¤ºä¾‹

æœ¬æ–‡æ¡£æŒ‡å¯¼å¦‚ä½•é€šè¿‡ `http://localhost:1234/v1/chat/completions` è°ƒç”¨ **LM Studio API** æ¥ä½¿ç”¨å„ç§ GGUF æ¨¡å‹ã€‚
åªéœ€å¤åˆ¶ç›¸åº”çš„å‘½ä»¤å—å¹¶åœ¨ç»ˆç«¯ä¸­è¿è¡Œå³å¯ã€‚
ä½¿ç”¨å‰ï¼Œéœ€è¦åœ¨ LM Studio ä¸­å°†æ¨¡å‹åŠ è½½åˆ° GPU ä¸Šã€‚

---

## ğŸ¦‰ Hermes 3 â€” Llama 3.1 8B (Q4_K_M)

**æ¨¡å‹æ–‡ä»¶ï¼š** `Hermes-3-Llama-3.1-8B.Q4_K_M.gguf`
**API æ¨¡å‹ IDï¼š** `hermes-3-llama-3.1-8b`

```bash
curl http://localhost:1234/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "hermes-3-llama-3.1-8b",
    "messages": [
      { "role": "system", "content": "Always answer in rhymes. Today is Thursday" },
      { "role": "user", "content": "What day is it today?" }
    ],
    "temperature": 0.7,
    "max_tokens": -1,
    "stream": false
}'
```

---

## ğŸ‰ Deepseek 0528 distill QWen3 â€” 8B (Q4_K_M)

**æ¨¡å‹æ–‡ä»¶ï¼š** `DeepSeek-R1-0528-Qwen3-8B-Q4_K_M.gguf`
**API æ¨¡å‹ IDï¼š** `deepseek/deepseek-r1-0528-qwen3-8b`

```bash
curl http://localhost:1234/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "deepseek/deepseek-r1-0528-qwen3-8b",
    "messages": [
        {
            "role": "system",
            "content": "Always answer in rhymes. Today is Thursday"
        },
        {
            "role": "user",
            "content": "What day is it today?"
        }
    ],
    "temperature": 0.7,
    "max_tokens": -1,
    "stream": false
}'
```
---

## ğŸ‰ é€šä¹‰åƒé—® 3 â€” 8B (Q6_K)

**æ¨¡å‹æ–‡ä»¶ï¼š** `Qwen3-8B-Q6_K.gguf`
**API æ¨¡å‹ IDï¼š** `qwen3-8b`

```bash
curl http://localhost:1234/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "qwen3-8b",
    "messages": [
      { "role": "system", "content": "Always answer in rhymes. Today is Thursday" },
      { "role": "user", "content": "What day is it today?" }
    ],
    "temperature": 0.7,
    "max_tokens": -1,
    "stream": false
}'
```

---

## ğŸ‰ é€šä¹‰åƒé—® 3 â€” 14B (Q4_K_M)

**æ¨¡å‹æ–‡ä»¶ï¼š** `Qwen3-14B-Q4_K_M.gguf`
**API æ¨¡å‹ IDï¼š** `qwen3-14b`

```bash
curl http://localhost:1234/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "qwen3-14b",
    "messages": [
      { "role": "system", "content": "Always answer in rhymes. Today is Thursday" },
      { "role": "user", "content": "What day is it today?" }
    ],
    "temperature": 0.7,
    "max_tokens": -1,
    "stream": false
}'
```

---

## ğŸ¦™ Meta Llama 3.1 â€” 8B æŒ‡ä»¤ (Q5_K_M)

**æ¨¡å‹æ–‡ä»¶ï¼š** `Meta-Llama-3.1-8B-Instruct-Q5_K_M.gguf`
**API æ¨¡å‹ IDï¼š** `meta-llama-3.1-8b-instruct@q5_k_m`

```bash
curl http://localhost:1234/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "meta-llama-3.1-8b-instruct@q5_k_m",
    "messages": [
      { "role": "system", "content": "Always answer in rhymes. Today is Thursday" },
      { "role": "user", "content": "What day is it today?" }
    ],
    "temperature": 0.7,
    "max_tokens": -1,
    "stream": false
}'
```

---

## ğŸ¦™ Meta Llama 3.1 â€” 8B æŒ‡ä»¤ (Q6_K)

**æ¨¡å‹æ–‡ä»¶ï¼š** `Meta-Llama-3.1-8B-Instruct-Q6_K.gguf`
**API æ¨¡å‹ IDï¼š** `meta-llama-3.1-8b-instruct@q6_k`

```bash
curl http://localhost:1234/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "meta-llama-3.1-8b-instruct@q6_k",
    "messages": [
      { "role": "system", "content": "Always answer in rhymes. Today is Thursday" },
      { "role": "user", "content": "What day is it today?" }
    ],
    "temperature": 0.7,
    "max_tokens": -1,
    "stream": false
}'
```

---

## ğŸ¦™ Meta Llama 3.1 â€” 8B æŒ‡ä»¤ (Q8_0)

**æ¨¡å‹æ–‡ä»¶ï¼š** `Meta-Llama-3.1-8B-Instruct-Q8_0.gguf`
**API æ¨¡å‹ IDï¼š** `meta-llama-3.1-8b-instruct@q8_0`

```bash
curl http://localhost:1234/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "meta-llama-3.1-8b-instruct@q8_0",
    "messages": [
      { "role": "system", "content": "Always answer in rhymes. Today is Thursday" },
      { "role": "user", "content": "What day is it today?" }
    ],
    "temperature": 0.7,
    "max_tokens": -1,
    "stream": false
}'
```

---

