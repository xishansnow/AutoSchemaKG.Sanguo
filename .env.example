# Use real LLM
USE_REAL_LLM=true
#TOGETHER_API_KEY=*** # Don't share your API key publicly

# Model settings
MODEL_NAME=meta-llama/Llama-3.3-70B-Instruct-Turbo-Free # Replace with your local model name
LM_STUDIO_BASE_URL=http://localhost:1234/v1 # local model URL
MODEL_TEMPERATURE=0.1
MODEL_MAX_TOKENS=2000

# File paths
INPUT_FILE=data/sanguo_origin.txt
OUTPUT_DIR=output